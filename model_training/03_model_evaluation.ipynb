{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model # Assuming Keras model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder # For consistency, though classes are loaded\n",
    "\n",
    "# Ensure backend.main can be imported for majority_vote\n",
    "module_path = os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in locals() else os.getcwd(), '..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from backend.main import majority_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'saved_models/heart_murmur_model.h5' # Adjusted to .h5 as saved in 02_notebook\n",
    "EVAL_DATA_DIR = 'evaluation_data'\n",
    "\n",
    "# Load the trained model\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    # Try path relative to 'model_training' if CWD is project root\n",
    "    alt_model_path = os.path.join('model_training', MODEL_PATH)\n",
    "    if os.path.exists(alt_model_path):\n",
    "        MODEL_PATH = alt_model_path\n",
    "    else:\n",
    "        # Try evaluation_data directory as a fallback if model was saved there by mistake\n",
    "        eval_model_path = os.path.join(EVAL_DATA_DIR, os.path.basename(MODEL_PATH))\n",
    "        if os.path.exists(eval_model_path):\n",
    "            MODEL_PATH = eval_model_path\n",
    "        else:\n",
    "             # Try saved_models within model_training if notebook is run from root\n",
    "            root_model_path = os.path.join('model_training', 'saved_models', os.path.basename(MODEL_PATH))\n",
    "            if os.path.exists(root_model_path):\n",
    "                MODEL_PATH = root_model_path \n"
    "            else:\n",
    "                raise FileNotFoundError(f\"Trained model not found at {MODEL_PATH}, {alt_model_path}, {eval_model_path}, or {root_model_path}\")\n",
    "model = load_model(MODEL_PATH)\n",
    "print(f\"Model loaded from {MODEL_PATH}\")\n",
    "\n",
    "# Load evaluation data\n",
    "X_val = np.load(os.path.join(EVAL_DATA_DIR, 'X_val.npy'))\n",
    "y_val_orig_labels_list = np.load(os.path.join(EVAL_DATA_DIR, 'y_val_orig_labels.npy'), allow_pickle=True).tolist() # Load as list\n",
    "file_ids_val_list = np.load(os.path.join(EVAL_DATA_DIR, 'file_ids_val.npy'), allow_pickle=True).tolist() # Load as list\n",
    "label_encoder_classes = np.load(os.path.join(EVAL_DATA_DIR, 'label_encoder_classes.npy'), allow_pickle=True)\n",
    "\n",
    "# Reconstruct a LabelEncoder instance for consistency if needed, or just use classes for decoding\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = label_encoder_classes\n",
    "\n",
    "print(f\"Evaluation data loaded from {EVAL_DATA_DIR}:\")\n",
    "print(f\" - X_val shape: {X_val.shape}\")\n",
    "print(f\" - y_val_orig_labels_list length: {len(y_val_orig_labels_list)}\")\n",
    "print(f\" - file_ids_val_list length: {len(file_ids_val_list)}\")\n",
    "print(f\" - Label encoder classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw predictions (probabilities or logits) from the model\n",
    "y_pred_proba_windows = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels (integer encoded)\n",
    "y_pred_encoded_windows = np.argmax(y_pred_proba_windows, axis=1)\n",
    "\n",
    "# Decode integer encoded predictions to string labels\n",
    "y_pred_str_windows = label_encoder.inverse_transform(y_pred_encoded_windows)\n",
    "\n",
    "print(f\"Performed window-level predictions. Shape of y_pred_proba_windows: {y_pred_proba_windows.shape}\")\n",
    "print(f\"Example predicted encoded labels (first 10): {y_pred_encoded_windows[:10]}\")\n",
    "print(f\"Example predicted string labels (first 10): {y_pred_str_windows[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in a dictionary: {file_id: {'predicted_windows': [], 'true_label': ''}}\n",
    "file_level_data = {}\n",
    "\n",
    "for i, file_id in enumerate(file_ids_val_list):\n",
    "    if file_id not in file_level_data:\n",
    "        file_level_data[file_id] = {'predicted_windows': [], 'true_label': y_val_orig_labels_list[i]}\n",
    "    file_level_data[file_id]['predicted_windows'].append(y_pred_str_windows[i])\n",
    "\n",
    "y_true_file_level = []\n",
    "y_pred_file_level = []\n",
    "\n",
    "print(\"\\nAggregating window predictions to file-level predictions:\")\n",
    "for file_id, data in file_level_data.items():\n",
    "    true_label = data['true_label']\n",
    "    window_preds = data['predicted_windows']\n",
    "    \n",
    "    majority_voted_prediction = majority_vote(window_preds)\n",
    "    \n",
    "    y_true_file_level.append(true_label)\n",
    "    y_pred_file_level.append(majority_voted_prediction)\n",
    "    # print(f\"File: {file_id}, True: {true_label}, Window Preds: {window_preds}, Voted Pred: {majority_voted_prediction}\") # Optional: for debugging\n",
    "\n",
    "print(f\"Number of unique files for evaluation: {len(y_true_file_level)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent label order for classification_report if needed\n",
    "# report_labels = sorted(list(set(y_true_file_level + y_pred_file_level))) # Handles cases where some classes might be missing in preds\n",
    "\n",
    "accuracy = accuracy_score(y_true_file_level, y_pred_file_level)\n",
    "report = classification_report(y_true_file_level, y_pred_file_level, labels=label_encoder.classes_.tolist(), zero_division=0)\n",
    "# Using label_encoder.classes_.tolist() ensures all original classes are in the report\n",
    "\n",
    "print(f\"\\nFile-Level Evaluation Results (after majority vote):\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
